{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "109b16fb",
      "metadata": {},
      "source": [
        "# Smoking Dataset Model Training Notebook\n",
        "Models allowed: Logistic Regression, SVM, Neural Network (MLP)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "39a4ea45",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install scikit-learn scipy pandas numpy -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "54a914a9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>height(cm)</th>\n",
              "      <th>weight(kg)</th>\n",
              "      <th>waist(cm)</th>\n",
              "      <th>eyesight(left)</th>\n",
              "      <th>eyesight(right)</th>\n",
              "      <th>hearing(left)</th>\n",
              "      <th>hearing(right)</th>\n",
              "      <th>systolic</th>\n",
              "      <th>relaxation</th>\n",
              "      <th>...</th>\n",
              "      <th>HDL</th>\n",
              "      <th>LDL</th>\n",
              "      <th>hemoglobin</th>\n",
              "      <th>Urine protein</th>\n",
              "      <th>serum creatinine</th>\n",
              "      <th>AST</th>\n",
              "      <th>ALT</th>\n",
              "      <th>Gtp</th>\n",
              "      <th>dental caries</th>\n",
              "      <th>smoking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35</td>\n",
              "      <td>170</td>\n",
              "      <td>85</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>118</td>\n",
              "      <td>78</td>\n",
              "      <td>...</td>\n",
              "      <td>70</td>\n",
              "      <td>142</td>\n",
              "      <td>19.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>61</td>\n",
              "      <td>115</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>175</td>\n",
              "      <td>110</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>119</td>\n",
              "      <td>79</td>\n",
              "      <td>...</td>\n",
              "      <td>71</td>\n",
              "      <td>114</td>\n",
              "      <td>15.9</td>\n",
              "      <td>1</td>\n",
              "      <td>1.1</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45</td>\n",
              "      <td>155</td>\n",
              "      <td>65</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>110</td>\n",
              "      <td>80</td>\n",
              "      <td>...</td>\n",
              "      <td>57</td>\n",
              "      <td>112</td>\n",
              "      <td>13.7</td>\n",
              "      <td>3</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1090</td>\n",
              "      <td>1400</td>\n",
              "      <td>276</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>165</td>\n",
              "      <td>80</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>88</td>\n",
              "      <td>...</td>\n",
              "      <td>46</td>\n",
              "      <td>91</td>\n",
              "      <td>16.9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>32</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>165</td>\n",
              "      <td>60</td>\n",
              "      <td>81.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>109</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>47</td>\n",
              "      <td>92</td>\n",
              "      <td>14.9</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>26</td>\n",
              "      <td>28</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  eyesight(right)  \\\n",
              "0   35         170          85       97.0             0.9              0.9   \n",
              "1   20         175         110      110.0             0.7              0.9   \n",
              "2   45         155          65       86.0             0.9              0.9   \n",
              "3   45         165          80       94.0             0.8              0.7   \n",
              "4   20         165          60       81.0             1.5              0.1   \n",
              "\n",
              "   hearing(left)  hearing(right)  systolic  relaxation  ...  HDL  LDL  \\\n",
              "0              1               1       118          78  ...   70  142   \n",
              "1              1               1       119          79  ...   71  114   \n",
              "2              1               1       110          80  ...   57  112   \n",
              "3              1               1       158          88  ...   46   91   \n",
              "4              1               1       109          64  ...   47   92   \n",
              "\n",
              "   hemoglobin  Urine protein  serum creatinine   AST   ALT  Gtp  \\\n",
              "0        19.8              1               1.0    61   115  125   \n",
              "1        15.9              1               1.1    19    25   30   \n",
              "2        13.7              3               0.6  1090  1400  276   \n",
              "3        16.9              1               0.9    32    36   36   \n",
              "4        14.9              1               1.2    26    28   15   \n",
              "\n",
              "   dental caries  smoking  \n",
              "0              1        1  \n",
              "1              1        0  \n",
              "2              0        0  \n",
              "3              0        0  \n",
              "4              0        0  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.stats import loguniform, uniform\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.read_csv('train_dataset.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f5ab41",
      "metadata": {},
      "source": [
        "## Feature Engineering & Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "df4064e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "DATA PREPARATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Model                     Train Shape          Test Shape           Features\n",
            "----------------------------------------------------------------------\n",
            "Logistic Regression       (31187, 31)          (7797, 31)           31\n",
            "SVM                       (31187, 45)          (7797, 45)           45\n",
            "Neural Network (MLP)      (31187, 56)          (7797, 56)           56\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Class Distribution: {0: 24666, 1: 14318}\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# COMMON FEATURE ENGINEERING FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def add_common_features(data):\n",
        "    \"\"\"Base features shared by all models\"\"\"\n",
        "    df = data.copy()\n",
        "    \n",
        "    # Body Composition\n",
        "    df['BMI'] = df['weight(kg)'] / ((df['height(cm)'] / 100) ** 2)\n",
        "    df['Waist_Height_ratio'] = df['waist(cm)'] / df['height(cm)']\n",
        "    \n",
        "    # Blood Pressure\n",
        "    df['BP_ratio'] = df['systolic'] / (df['relaxation'] + 1)\n",
        "    \n",
        "    # Lipid Ratios\n",
        "    df['Chol_HDL_ratio'] = df['Cholesterol'] / (df['HDL'] + 1)\n",
        "    df['LDL_HDL_ratio'] = df['LDL'] / (df['HDL'] + 1)\n",
        "    df['Trig_HDL_ratio'] = df['triglyceride'] / (df['HDL'] + 1)\n",
        "    \n",
        "    # Liver Function\n",
        "    df['AST_ALT_ratio'] = df['AST'] / (df['ALT'] + 1)\n",
        "    \n",
        "    # Sensory\n",
        "    df['eyesight_avg'] = (df['eyesight(left)'] + df['eyesight(right)']) / 2\n",
        "    df['hearing_sum'] = df['hearing(left)'] + df['hearing(right)']\n",
        "    \n",
        "    return df\n",
        "\n",
        "def add_features_lr(data):\n",
        "    \"\"\"Logistic Regression: Common features only (simpler model)\"\"\"\n",
        "    return add_common_features(data)\n",
        "\n",
        "def add_features_svm(data):\n",
        "    \"\"\"SVM: Common + additional features\"\"\"\n",
        "    df = add_common_features(data)\n",
        "    \n",
        "    # Additional Body Features\n",
        "    df['Waist_Weight_ratio'] = df['waist(cm)'] / df['weight(kg)']\n",
        "    \n",
        "    # Blood Pressure Extended\n",
        "    df['pulse_pressure'] = df['systolic'] - df['relaxation']\n",
        "    df['MAP'] = (df['systolic'] + 2 * df['relaxation']) / 3\n",
        "    \n",
        "    # Lipid Extended\n",
        "    df['non_HDL_chol'] = df['Cholesterol'] - df['HDL']\n",
        "    df['atherogenic_index'] = np.log10(df['triglyceride'] / (df['HDL'] + 1) + 1)\n",
        "    \n",
        "    # Liver Extended\n",
        "    df['liver_enzyme_sum'] = df['AST'] + df['ALT'] + df['Gtp']\n",
        "    df['GTP_ALT_ratio'] = df['Gtp'] / (df['ALT'] + 1)\n",
        "    \n",
        "    # Sensory Extended\n",
        "    df['eyesight_diff'] = abs(df['eyesight(left)'] - df['eyesight(right)'])\n",
        "    \n",
        "    # Blood Features\n",
        "    df['hemoglobin_BMI'] = df['hemoglobin'] / (df['BMI'] + 1)\n",
        "    \n",
        "    # Age Interactions\n",
        "    df['age_hemoglobin'] = df['age'] * df['hemoglobin']\n",
        "    df['age_BMI'] = df['age'] * df['BMI']\n",
        "    df['age_systolic'] = df['age'] * df['systolic']\n",
        "    \n",
        "    # Composite Scores\n",
        "    df['metabolic_risk'] = (df['BMI'] / 25) + (df['Trig_HDL_ratio'] / 3) + (df['fasting blood sugar'] / 100)\n",
        "    df['cv_risk'] = (df['Chol_HDL_ratio'] / 4) + (df['systolic'] / 120) + (df['LDL'] / 100)\n",
        "    \n",
        "    return df\n",
        "\n",
        "def add_features_mlp(data):\n",
        "    \"\"\"MLP: Most comprehensive features\"\"\"\n",
        "    df = add_features_svm(data)  # Start with SVM features\n",
        "    \n",
        "    # Body Extended\n",
        "    df['BSA'] = np.sqrt((df['height(cm)'] * df['weight(kg)']) / 3600)\n",
        "    \n",
        "    # Blood Pressure Extended\n",
        "    df['hypertension_score'] = (df['systolic'] / 140) + (df['relaxation'] / 90)\n",
        "    \n",
        "    # Lipid Extended\n",
        "    df['total_lipids'] = df['Cholesterol'] + df['triglyceride'] + df['LDL']\n",
        "    \n",
        "    # Liver Log-transformed\n",
        "    df['log_GTP'] = np.log1p(df['Gtp'])\n",
        "    df['log_ALT'] = np.log1p(df['ALT'])\n",
        "    \n",
        "    # Sensory Extended\n",
        "    df['vision_score'] = (df['eyesight(left)'] + df['eyesight(right)']) * (1 + df['eyesight_diff'])\n",
        "    \n",
        "    # Blood Extended\n",
        "    df['hemoglobin_norm'] = df['hemoglobin'] / 15\n",
        "    \n",
        "    # Age Extended\n",
        "    df['age_cholesterol'] = df['age'] * df['Cholesterol']\n",
        "    df['age_squared'] = df['age'] ** 2\n",
        "    \n",
        "    # Health Score\n",
        "    df['health_score'] = (df['hemoglobin'] / 15) - (df['BMI'] / 30) - (df['Gtp'] / 50)\n",
        "    \n",
        "    # Dental\n",
        "    df['has_dental_issues'] = (df['dental caries'] == 1).astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# ============================================================\n",
        "# PREPARE DATA FOR ALL MODELS\n",
        "# ============================================================\n",
        "\n",
        "# Load test data once\n",
        "test_df_raw = pd.read_csv('test_dataset.csv')\n",
        "\n",
        "# Logistic Regression Data\n",
        "df_lr = add_features_lr(df.copy())\n",
        "X_lr = df_lr.drop('smoking', axis=1)\n",
        "y_lr = df_lr['smoking']\n",
        "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(\n",
        "    X_lr, y_lr, test_size=0.2, random_state=42, stratify=y_lr\n",
        ")\n",
        "test_df_lr = add_features_lr(test_df_raw.copy())\n",
        "\n",
        "# SVM Data\n",
        "df_svm = add_features_svm(df.copy())\n",
        "X_svm = df_svm.drop('smoking', axis=1)\n",
        "y_svm = df_svm['smoking']\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(\n",
        "    X_svm, y_svm, test_size=0.2, random_state=42, stratify=y_svm\n",
        ")\n",
        "test_df_svm = add_features_svm(test_df_raw.copy())\n",
        "\n",
        "# MLP Data\n",
        "df_mlp = add_features_mlp(df.copy())\n",
        "X_mlp = df_mlp.drop('smoking', axis=1)\n",
        "y_mlp = df_mlp['smoking']\n",
        "X_train_mlp, X_test_mlp, y_train_mlp, y_test_mlp = train_test_split(\n",
        "    X_mlp, y_mlp, test_size=0.2, random_state=42, stratify=y_mlp\n",
        ")\n",
        "test_df_mlp = add_features_mlp(test_df_raw.copy())\n",
        "\n",
        "# Print Summary\n",
        "print(\"=\"*70)\n",
        "print(\"DATA PREPARATION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n{'Model':<25} {'Train Shape':<20} {'Test Shape':<20} {'Features'}\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'Logistic Regression':<25} {str(X_train_lr.shape):<20} {str(X_test_lr.shape):<20} {X_train_lr.shape[1]}\")\n",
        "print(f\"{'SVM':<25} {str(X_train_svm.shape):<20} {str(X_test_svm.shape):<20} {X_train_svm.shape[1]}\")\n",
        "print(f\"{'Neural Network (MLP)':<25} {str(X_train_mlp.shape):<20} {str(X_test_mlp.shape):<20} {X_train_mlp.shape[1]}\")\n",
        "print(\"-\"*70)\n",
        "print(f\"\\nClass Distribution: {y_lr.value_counts().to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b4ff742",
      "metadata": {},
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f7122f9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "Rank 1:\n",
            "  C=0.039054, penalty=elasticnet, l1_ratio=0.5248\n",
            "  CV Accuracy = 0.7389 (+/- 0.0028)\n",
            "\n",
            "Rank 2:\n",
            "  C=0.047315, penalty=l1, l1_ratio=0.0581\n",
            "  CV Accuracy = 0.7350 (+/- 0.0038)\n",
            "\n",
            "Rank 3:\n",
            "  C=0.017670, penalty=l1, l1_ratio=0.1834\n",
            "  CV Accuracy = 0.7346 (+/- 0.0036)\n",
            "\n",
            "Rank 4:\n",
            "  C=0.001233, penalty=l2, l1_ratio=0.6175\n",
            "  CV Accuracy = 0.7335 (+/- 0.0030)\n",
            "\n",
            "Rank 5:\n",
            "  C=1.771885, penalty=l2, l1_ratio=0.0564\n",
            "  CV Accuracy = 0.7235 (+/- 0.0039)\n",
            "\n",
            "Best CV Accuracy: 0.7389\n",
            "\n",
            "Test Accuracy: 0.7352\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.79      0.79      4933\n",
            "           1       0.64      0.64      0.64      2864\n",
            "\n",
            "    accuracy                           0.74      7797\n",
            "   macro avg       0.71      0.71      0.71      7797\n",
            "weighted avg       0.73      0.74      0.73      7797\n",
            "\n",
            "Submission 'logistic_submission.csv' created: 16708 predictions\n"
          ]
        }
      ],
      "source": [
        "# Pipeline with scaling and polynomial features\n",
        "pipeline_lr = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
        "    ('logreg', LogisticRegression(max_iter=3000, solver='saga', random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter distributions\n",
        "param_dist_lr = {\n",
        "    'logreg__C': loguniform(0.0001, 100),\n",
        "    'logreg__penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'logreg__l1_ratio': uniform(0, 1),\n",
        "    'logreg__class_weight': [None, 'balanced'],\n",
        "    'logreg__tol': loguniform(1e-6, 1e-2),\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV\n",
        "random_search_lr = RandomizedSearchCV(\n",
        "    pipeline_lr, param_dist_lr, n_iter=10, cv=5, scoring='accuracy', \n",
        "    n_jobs=-1, verbose=1, random_state=42, return_train_score=True\n",
        ")\n",
        "random_search_lr.fit(X_train_lr, y_train_lr)\n",
        "\n",
        "# Top 5 results\n",
        "results_lr = pd.DataFrame(random_search_lr.cv_results_).sort_values('rank_test_score')\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "# print(\"=== LOGISTIC REGRESSION: Top 5 Parameter Combinations ===\")\n",
        "print(\"=\"*60)\n",
        "for _, row in results_lr.head(5).iterrows():\n",
        "    print(f\"\\nRank {int(row['rank_test_score'])}:\")\n",
        "    print(f\"  C={row['param_logreg__C']:.6f}, penalty={row['param_logreg__penalty']}, \"\n",
        "          f\"l1_ratio={row['param_logreg__l1_ratio']:.4f}\")\n",
        "    print(f\"  CV Accuracy = {row['mean_test_score']:.4f} (+/- {row['std_test_score']:.4f})\")\n",
        "\n",
        "print(f\"\\nBest CV Accuracy: {random_search_lr.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate and predict\n",
        "best_logreg = random_search_lr.best_estimator_\n",
        "y_pred_lr = best_logreg.predict(X_test_lr)\n",
        "print(f\"\\nTest Accuracy: {accuracy_score(y_test_lr, y_pred_lr):.4f}\")\n",
        "print(classification_report(y_test_lr, y_pred_lr))\n",
        "\n",
        "# Submission\n",
        "submission_lr = pd.DataFrame({\n",
        "    'id': range(len(test_df_lr)),\n",
        "    'smoking': best_logreg.predict(test_df_lr)\n",
        "})\n",
        "submission_lr.to_csv('logistic_submission.csv', index=False)\n",
        "print(f\"Submission 'logistic_submission.csv' created: {len(submission_lr)} predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b54dd4ac",
      "metadata": {},
      "source": [
        "## Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "48f80533",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting SVM training (1 models, 5-fold CV)...\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "Rank 1:\n",
            "  C=0.3149, kernel=sigmoid, gamma=0.08471801418819976\n",
            "  CV Accuracy = 0.6193 (+/- 0.0035)\n",
            "\n",
            "Best CV Accuracy: 0.6193\n",
            "\n",
            "Test Accuracy: 0.6054\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.69      0.69      4933\n",
            "           1       0.46      0.46      0.46      2864\n",
            "\n",
            "    accuracy                           0.61      7797\n",
            "   macro avg       0.58      0.58      0.58      7797\n",
            "weighted avg       0.61      0.61      0.61      7797\n",
            "\n",
            "Submission 'svm_submission.csv' created: 16708 predictions\n"
          ]
        }
      ],
      "source": [
        "# Pipeline\n",
        "pipeline_svm = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(random_state=42, cache_size=1000))\n",
        "])\n",
        "\n",
        "# Hyperparameter distributions\n",
        "param_dist_svm = {\n",
        "    'svm__C': loguniform(0.01, 100),\n",
        "    'svm__kernel': ['rbf', 'poly', 'sigmoid', 'linear'],\n",
        "    'svm__gamma': ['scale', 'auto'] + list(loguniform(1e-4, 1).rvs(8, random_state=42)),\n",
        "    'svm__degree': [2, 3, 4],\n",
        "    'svm__coef0': uniform(0, 1),\n",
        "    'svm__class_weight': [None, 'balanced'],\n",
        "    'svm__shrinking': [True, False],\n",
        "    'svm__tol': loguniform(1e-5, 1e-2),\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV\n",
        "random_search_svm = RandomizedSearchCV(\n",
        "    pipeline_svm, param_dist_svm, n_iter=1, cv=5, scoring='accuracy',\n",
        "    n_jobs=-1, verbose=2, random_state=42, return_train_score=True\n",
        ")\n",
        "\n",
        "print(\"Starting SVM training (1 models, 5-fold CV)...\")\n",
        "random_search_svm.fit(X_train_svm, y_train_svm)\n",
        "\n",
        "# Top 5 results\n",
        "results_svm = pd.DataFrame(random_search_svm.cv_results_).sort_values('rank_test_score')\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "# print(\"=== SVM: Top 5 Parameter Combinations ===\")\n",
        "print(\"=\"*60)\n",
        "for _, row in results_svm.head(5).iterrows():\n",
        "    print(f\"\\nRank {int(row['rank_test_score'])}:\")\n",
        "    print(f\"  C={row['param_svm__C']:.4f}, kernel={row['param_svm__kernel']}, gamma={row['param_svm__gamma']}\")\n",
        "    print(f\"  CV Accuracy = {row['mean_test_score']:.4f} (+/- {row['std_test_score']:.4f})\")\n",
        "\n",
        "print(f\"\\nBest CV Accuracy: {random_search_svm.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate and predict\n",
        "best_svm = random_search_svm.best_estimator_\n",
        "y_pred_svm = best_svm.predict(X_test_svm)\n",
        "print(f\"\\nTest Accuracy: {accuracy_score(y_test_svm, y_pred_svm):.4f}\")\n",
        "print(classification_report(y_test_svm, y_pred_svm))\n",
        "\n",
        "# Submission\n",
        "submission_svm = pd.DataFrame({\n",
        "    'id': range(len(test_df_svm)),\n",
        "    'smoking': best_svm.predict(test_df_svm)\n",
        "})\n",
        "submission_svm.to_csv('svm_submission.csv', index=False)\n",
        "print(f\"Submission 'svm_submission.csv' created: {len(submission_svm)} predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "010f4b02",
      "metadata": {},
      "source": [
        "## Neural Network (MLPClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fa77f945",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting MLP training (15 models, 5-fold CV)...\n",
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
            "\n",
            "============================================================\n",
            "=== MLP: Top 5 Parameter Combinations ===\n",
            "============================================================\n",
            "\n",
            "Rank 1:\n",
            "  Fitting 5 folds for each of 15 candidateslayers=(256, 128), activation=logistic\n",
            "  solver=adam, lr_init=0.004828\n",
            "  CV Accuracy = 0.7553 (+/- 0.0009)\n",
            "\n",
            "Rank 2:\n",
            "  Fitting 5 folds for each of 15 candidateslayers=(64, 32), activation=tanh\n",
            "  solver=adam, lr_init=0.003355\n",
            "  CV Accuracy = 0.7536 (+/- 0.0026)\n",
            "\n",
            "Rank 3:\n",
            "  Fitting 5 folds for each of 15 candidateslayers=(128,), activation=relu\n",
            "  solver=sgd, lr_init=0.000820\n",
            "  CV Accuracy = 0.7528 (+/- 0.0052)\n",
            "\n",
            "Rank 4:\n",
            "  Fitting 5 folds for each of 15 candidateslayers=(100, 50, 25), activation=logistic\n",
            "  solver=adam, lr_init=0.013200\n",
            "  CV Accuracy = 0.7523 (+/- 0.0023)\n",
            "\n",
            "Rank 5:\n",
            "  Fitting 5 folds for each of 15 candidateslayers=(128, 64, 32), activation=relu\n",
            "  solver=adam, lr_init=0.007411\n",
            "  CV Accuracy = 0.7509 (+/- 0.0015)\n",
            "\n",
            "Best CV Accuracy: 0.7553\n",
            "\n",
            "Test Accuracy: 0.7530\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81      4933\n",
            "           1       0.67      0.64      0.66      2864\n",
            "\n",
            "    accuracy                           0.75      7797\n",
            "   macro avg       0.73      0.73      0.73      7797\n",
            "weighted avg       0.75      0.75      0.75      7797\n",
            "\n",
            "Submission 'mlp_submission.csv' created: 16708 predictions\n"
          ]
        }
      ],
      "source": [
        " # Pipeline\n",
        "pipeline_mlp = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('mlp', MLPClassifier(random_state=42, early_stopping=True, validation_fraction=0.1))\n",
        "])\n",
        "\n",
        "# Hyperparameter distributions\n",
        "param_dist_mlp = {\n",
        "    'mlp__hidden_layer_sizes': [\n",
        "        (64,), (128,), (256,),\n",
        "        (64, 32), (128, 64), (256, 128),\n",
        "        (128, 64, 32), (256, 128, 64),\n",
        "        (64, 64), (128, 128), (100, 50, 25)\n",
        "    ],\n",
        "    'mlp__activation': ['relu', 'tanh', 'logistic'],\n",
        "    'mlp__solver': ['adam', 'sgd'],\n",
        "    'mlp__learning_rate': ['constant', 'adaptive', 'invscaling'],\n",
        "    'mlp__learning_rate_init': loguniform(1e-4, 1e-1),\n",
        "    'mlp__alpha': loguniform(1e-5, 1e-1),\n",
        "    'mlp__batch_size': [32, 64, 128, 256],\n",
        "    'mlp__max_iter': [300, 500, 700, 1000],\n",
        "    'mlp__beta_1': uniform(0.85, 0.14),\n",
        "    'mlp__beta_2': uniform(0.99, 0.009),\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV\n",
        "random_search_mlp = RandomizedSearchCV(\n",
        "    pipeline_mlp, param_dist_mlp, n_iter=15, cv=5, scoring='accuracy',\n",
        "    n_jobs=-1, verbose=2, random_state=42, return_train_score=True\n",
        ")\n",
        "\n",
        "print(\"Starting MLP training (15 models, 5-fold CV)...\")\n",
        "random_search_mlp.fit(X_train_mlp, y_train_mlp)\n",
        "\n",
        "# Top 5 results\n",
        "results_mlp = pd.DataFrame(random_search_mlp.cv_results_).sort_values('rank_test_score')\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"=== MLP: Top 5 Parameter Combinations ===\")\n",
        "print(\"=\"*60)\n",
        "for _, row in results_mlp.head(5).iterrows():\n",
        "    print(f\"\\nRank {int(row['rank_test_score'])}:\")\n",
        "    print(f\"  Fitting 5 folds for each of 15 candidateslayers={row['param_mlp__hidden_layer_sizes']}, activation={row['param_mlp__activation']}\")\n",
        "    print(f\"  solver={row['param_mlp__solver']}, lr_init={row['param_mlp__learning_rate_init']:.6f}\")\n",
        "    print(f\"  CV Accuracy = {row['mean_test_score']:.4f} (+/- {row['std_test_score']:.4f})\")\n",
        "\n",
        "print(f\"\\nBest CV Accuracy: {random_search_mlp.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate and predict\n",
        "best_mlp = random_search_mlp.best_estimator_\n",
        "y_pred_mlp = best_mlp.predict(X_test_mlp)\n",
        "print(f\"\\nTest Accuracy: {accuracy_score(y_test_mlp, y_pred_mlp):.4f}\")\n",
        "print(classification_report(y_test_mlp, y_pred_mlp))\n",
        "\n",
        "# Submission\n",
        "submission_mlp = pd.DataFrame({\n",
        "    'id': range(len(test_df_mlp)),\n",
        "    'smoking': best_mlp.predict(test_df_mlp)\n",
        "})\n",
        "submission_mlp.to_csv('mlp_submission.csv', index=False)\n",
        "print(f\"Submission 'mlp_submission.csv' created: {len(submission_mlp)} predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "599cb515",
      "metadata": {},
      "source": [
        "## Model Comparison - Classification Scores Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4124fe68",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                    FINAL MODEL COMPARISON\n",
            "================================================================================\n",
            "\n",
            "MODEL                         ACCURACY    PRECISION       RECALL     F1-SCORE\n",
            "--------------------------------------------------------------------------------\n",
            "Logistic Regression             0.7352       0.7348       0.7352       0.7349\n",
            "SVM                             0.6054       0.6054       0.6054       0.6054\n",
            "Neural Network (MLP)            0.7530       0.7510       0.7530       0.7518\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üèÜ BEST MODEL: Neural Network (MLP) (Accuracy: 0.7530)\n",
            "\n",
            "================================================================================\n",
            "SUMMARY TABLE\n",
            "================================================================================\n",
            "                      Test Accuracy  Precision  Recall  F1-Score  CV Score\n",
            "Neural Network (MLP)         0.7530     0.7510  0.7530    0.7518    0.7553\n",
            "Logistic Regression          0.7352     0.7348  0.7352    0.7349    0.7389\n",
            "SVM                          0.6054     0.6054  0.6054    0.6054    0.6193\n",
            "\n",
            "================================================================================\n",
            "SUBMISSION FILES: logistic_submission.csv, svm_submission.csv, mlp_submission.csv\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "#                    MODEL COMPARISON SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "# Collect all results\n",
        "models_data = {\n",
        "    'Logistic Regression': {\n",
        "        'y_test': y_test_lr, 'y_pred': y_pred_lr, 'cv_score': random_search_lr.best_score_\n",
        "    },\n",
        "    'SVM': {\n",
        "        'y_test': y_test_svm, 'y_pred': y_pred_svm, 'cv_score': random_search_svm.best_score_\n",
        "    },\n",
        "    'Neural Network (MLP)': {\n",
        "        'y_test': y_test_mlp, 'y_pred': y_pred_mlp, 'cv_score': random_search_mlp.best_score_\n",
        "    }\n",
        "}\n",
        "\n",
        "# Calculate metrics\n",
        "model_results = {}\n",
        "for name, data in models_data.items():\n",
        "    model_results[name] = {\n",
        "        'Test Accuracy': accuracy_score(data['y_test'], data['y_pred']),\n",
        "        'Precision': precision_score(data['y_test'], data['y_pred'], average='weighted'),\n",
        "        'Recall': recall_score(data['y_test'], data['y_pred'], average='weighted'),\n",
        "        'F1-Score': f1_score(data['y_test'], data['y_pred'], average='weighted'),\n",
        "        'CV Score': data['cv_score']\n",
        "    }\n",
        "\n",
        "# Print comparison table\n",
        "print(\"=\"*80)\n",
        "print(\"                    FINAL MODEL COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n{'MODEL':<25} {'ACCURACY':>12} {'PRECISION':>12} {'RECALL':>12} {'F1-SCORE':>12}\")\n",
        "print(\"-\"*80)\n",
        "for name, scores in model_results.items():\n",
        "    print(f\"{name:<25} {scores['Test Accuracy']:>12.4f} {scores['Precision']:>12.4f} \"\n",
        "          f\"{scores['Recall']:>12.4f} {scores['F1-Score']:>12.4f}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Best model\n",
        "best_model = max(model_results, key=lambda x: model_results[x]['Test Accuracy'])\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model} (Accuracy: {model_results[best_model]['Test Accuracy']:.4f})\")\n",
        "\n",
        "# Summary DataFrame\n",
        "summary_df = pd.DataFrame(model_results).T.round(4).sort_values('Test Accuracy', ascending=False)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY TABLE\")\n",
        "print(\"=\"*80)\n",
        "print(summary_df)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUBMISSION FILES: logistic_submission.csv, svm_submission.csv, mlp_submission.csv\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
