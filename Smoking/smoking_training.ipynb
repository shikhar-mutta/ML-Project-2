{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "109b16fb",
      "metadata": {},
      "source": [
        "# Smoking Dataset Model Training Notebook\n",
        "Models allowed: Logistic Regression, SVM, Neural Network (MLP)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a914a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.stats import loguniform, uniform\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.read_csv('train_dataset.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f5ab41",
      "metadata": {},
      "source": [
        "## Feature Engineering & Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4064e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "DATA PREPARATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Model                     Train Shape          Test Shape           Features\n",
            "----------------------------------------------------------------------\n",
            "Logistic Regression       (31187, 31)          (7797, 31)           31\n",
            "SVM                       (31187, 45)          (7797, 45)           45\n",
            "Neural Network (MLP)      (31187, 56)          (7797, 56)           56\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Class Distribution: {0: 24666, 1: 14318}\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# COMMON FEATURE ENGINEERING FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def add_common_features(data):\n",
        "    \"\"\"Base features shared by all models\"\"\"\n",
        "    df = data.copy()\n",
        "    \n",
        "    # Body Composition\n",
        "    df['BMI'] = df['weight(kg)'] / ((df['height(cm)'] / 100) ** 2)\n",
        "    df['Waist_Height_ratio'] = df['waist(cm)'] / df['height(cm)']\n",
        "    \n",
        "    # Blood Pressure\n",
        "    df['BP_ratio'] = df['systolic'] / (df['relaxation'] + 1)\n",
        "    \n",
        "    # Lipid Ratios\n",
        "    df['Chol_HDL_ratio'] = df['Cholesterol'] / (df['HDL'] + 1)\n",
        "    df['LDL_HDL_ratio'] = df['LDL'] / (df['HDL'] + 1)\n",
        "    df['Trig_HDL_ratio'] = df['triglyceride'] / (df['HDL'] + 1)\n",
        "    \n",
        "    # Liver Function\n",
        "    df['AST_ALT_ratio'] = df['AST'] / (df['ALT'] + 1)\n",
        "    \n",
        "    # Sensory\n",
        "    df['eyesight_avg'] = (df['eyesight(left)'] + df['eyesight(right)']) / 2\n",
        "    df['hearing_sum'] = df['hearing(left)'] + df['hearing(right)']\n",
        "    \n",
        "    return df\n",
        "\n",
        "def add_features_lr(data):\n",
        "    \"\"\"Logistic Regression: Common features only (simpler model)\"\"\"\n",
        "    return add_common_features(data)\n",
        "\n",
        "def add_features_svm(data):\n",
        "    \"\"\"SVM: Common + additional features\"\"\"\n",
        "    df = add_common_features(data)\n",
        "    \n",
        "    # Additional Body Features\n",
        "    df['Waist_Weight_ratio'] = df['waist(cm)'] / df['weight(kg)']\n",
        "    \n",
        "    # Blood Pressure Extended\n",
        "    df['pulse_pressure'] = df['systolic'] - df['relaxation']\n",
        "    df['MAP'] = (df['systolic'] + 2 * df['relaxation']) / 3\n",
        "    \n",
        "    # Lipid Extended\n",
        "    df['non_HDL_chol'] = df['Cholesterol'] - df['HDL']\n",
        "    df['atherogenic_index'] = np.log10(df['triglyceride'] / (df['HDL'] + 1) + 1)\n",
        "    \n",
        "    # Liver Extended\n",
        "    df['liver_enzyme_sum'] = df['AST'] + df['ALT'] + df['Gtp']\n",
        "    df['GTP_ALT_ratio'] = df['Gtp'] / (df['ALT'] + 1)\n",
        "    \n",
        "    # Sensory Extended\n",
        "    df['eyesight_diff'] = abs(df['eyesight(left)'] - df['eyesight(right)'])\n",
        "    \n",
        "    # Blood Features\n",
        "    df['hemoglobin_BMI'] = df['hemoglobin'] / (df['BMI'] + 1)\n",
        "    \n",
        "    # Age Interactions\n",
        "    df['age_hemoglobin'] = df['age'] * df['hemoglobin']\n",
        "    df['age_BMI'] = df['age'] * df['BMI']\n",
        "    df['age_systolic'] = df['age'] * df['systolic']\n",
        "    \n",
        "    # Composite Scores\n",
        "    df['metabolic_risk'] = (df['BMI'] / 25) + (df['Trig_HDL_ratio'] / 3) + (df['fasting blood sugar'] / 100)\n",
        "    df['cv_risk'] = (df['Chol_HDL_ratio'] / 4) + (df['systolic'] / 120) + (df['LDL'] / 100)\n",
        "    \n",
        "    return df\n",
        "\n",
        "def add_features_mlp(data):\n",
        "    \"\"\"MLP: Most comprehensive features\"\"\"\n",
        "    df = add_features_svm(data)  # Start with SVM features\n",
        "    \n",
        "    # Body Extended\n",
        "    df['BSA'] = np.sqrt((df['height(cm)'] * df['weight(kg)']) / 3600)\n",
        "    \n",
        "    # Blood Pressure Extended\n",
        "    df['hypertension_score'] = (df['systolic'] / 140) + (df['relaxation'] / 90)\n",
        "    \n",
        "    # Lipid Extended\n",
        "    df['total_lipids'] = df['Cholesterol'] + df['triglyceride'] + df['LDL']\n",
        "    \n",
        "    # Liver Log-transformed\n",
        "    df['log_GTP'] = np.log1p(df['Gtp'])\n",
        "    df['log_ALT'] = np.log1p(df['ALT'])\n",
        "    \n",
        "    # Sensory Extended\n",
        "    df['vision_score'] = (df['eyesight(left)'] + df['eyesight(right)']) * (1 + df['eyesight_diff'])\n",
        "    \n",
        "    # Blood Extended\n",
        "    df['hemoglobin_norm'] = df['hemoglobin'] / 15\n",
        "    \n",
        "    # Age Extended\n",
        "    df['age_cholesterol'] = df['age'] * df['Cholesterol']\n",
        "    df['age_squared'] = df['age'] ** 2\n",
        "    \n",
        "    # Health Score\n",
        "    df['health_score'] = (df['hemoglobin'] / 15) - (df['BMI'] / 30) - (df['Gtp'] / 50)\n",
        "    \n",
        "    # Dental\n",
        "    df['has_dental_issues'] = (df['dental caries'] == 1).astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# ============================================================\n",
        "# PREPARE DATA FOR ALL MODELS\n",
        "# ============================================================\n",
        "\n",
        "# Load test data once\n",
        "test_df_raw = pd.read_csv('test_dataset.csv')\n",
        "\n",
        "# Logistic Regression Data\n",
        "df_lr = add_features_lr(df.copy())\n",
        "X_lr = df_lr.drop('smoking', axis=1)\n",
        "y_lr = df_lr['smoking']\n",
        "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(\n",
        "    X_lr, y_lr, test_size=0.2, random_state=42, stratify=y_lr\n",
        ")\n",
        "test_df_lr = add_features_lr(test_df_raw.copy())\n",
        "\n",
        "# SVM Data\n",
        "df_svm = add_features_svm(df.copy())\n",
        "X_svm = df_svm.drop('smoking', axis=1)\n",
        "y_svm = df_svm['smoking']\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(\n",
        "    X_svm, y_svm, test_size=0.2, random_state=42, stratify=y_svm\n",
        ")\n",
        "test_df_svm = add_features_svm(test_df_raw.copy())\n",
        "\n",
        "# MLP Data\n",
        "df_mlp = add_features_mlp(df.copy())\n",
        "X_mlp = df_mlp.drop('smoking', axis=1)\n",
        "y_mlp = df_mlp['smoking']\n",
        "X_train_mlp, X_test_mlp, y_train_mlp, y_test_mlp = train_test_split(\n",
        "    X_mlp, y_mlp, test_size=0.2, random_state=42, stratify=y_mlp\n",
        ")\n",
        "test_df_mlp = add_features_mlp(test_df_raw.copy())\n",
        "\n",
        "# Print Summary\n",
        "print(\"=\"*70)\n",
        "print(\"DATA PREPARATION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n{'Model':<25} {'Train Shape':<20} {'Test Shape':<20} {'Features'}\")\n",
        "print(\"-\"*70)\n",
        "print(f\"{'Logistic Regression':<25} {str(X_train_lr.shape):<20} {str(X_test_lr.shape):<20} {X_train_lr.shape[1]}\")\n",
        "print(f\"{'SVM':<25} {str(X_train_svm.shape):<20} {str(X_test_svm.shape):<20} {X_train_svm.shape[1]}\")\n",
        "print(f\"{'Neural Network (MLP)':<25} {str(X_train_mlp.shape):<20} {str(X_test_mlp.shape):<20} {X_train_mlp.shape[1]}\")\n",
        "print(\"-\"*70)\n",
        "print(f\"\\nClass Distribution: {y_lr.value_counts().to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b4ff742",
      "metadata": {},
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7122f9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        }
      ],
      "source": [
        "# Pipeline with scaling and polynomial features\n",
        "pipeline_lr = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
        "    ('logreg', LogisticRegression(max_iter=3000, solver='saga', random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter distributions\n",
        "param_dist_lr = {\n",
        "    'logreg__C': loguniform(0.0001, 100),\n",
        "    'logreg__penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'logreg__l1_ratio': uniform(0, 1),\n",
        "    'logreg__class_weight': [None, 'balanced'],\n",
        "    'logreg__tol': loguniform(1e-6, 1e-2),\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV\n",
        "random_search_lr = RandomizedSearchCV(\n",
        "    pipeline_lr, param_dist_lr, n_iter=15, cv=5, scoring='accuracy', \n",
        "    n_jobs=-1, verbose=1, random_state=42, return_train_score=True\n",
        ")\n",
        "random_search_lr.fit(X_train_lr, y_train_lr)\n",
        "\n",
        "# Top 5 results\n",
        "results_lr = pd.DataFrame(random_search_lr.cv_results_).sort_values('rank_test_score')\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"=== LOGISTIC REGRESSION: Top 5 Parameter Combinations ===\")\n",
        "print(\"=\"*60)\n",
        "for _, row in results_lr.head(5).iterrows():\n",
        "    print(f\"\\nRank {int(row['rank_test_score'])}:\")\n",
        "    print(f\"  C={row['param_logreg__C']:.6f}, penalty={row['param_logreg__penalty']}, \"\n",
        "          f\"l1_ratio={row['param_logreg__l1_ratio']:.4f}\")\n",
        "    print(f\"  CV Accuracy = {row['mean_test_score']:.4f} (+/- {row['std_test_score']:.4f})\")\n",
        "\n",
        "print(f\"\\nBest CV Accuracy: {random_search_lr.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate and predict\n",
        "best_logreg = random_search_lr.best_estimator_\n",
        "y_pred_lr = best_logreg.predict(X_test_lr)\n",
        "print(f\"\\nTest Accuracy: {accuracy_score(y_test_lr, y_pred_lr):.4f}\")\n",
        "print(classification_report(y_test_lr, y_pred_lr))\n",
        "\n",
        "# Submission\n",
        "submission_lr = pd.DataFrame({\n",
        "    'id': range(len(test_df_lr)),\n",
        "    'smoking': best_logreg.predict(test_df_lr)\n",
        "})\n",
        "submission_lr.to_csv('logistic_submission.csv', index=False)\n",
        "print(f\"Submission 'logistic_submission.csv' created: {len(submission_lr)} predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b54dd4ac",
      "metadata": {},
      "source": [
        "## Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c9baf0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline\n",
        "pipeline_svm = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(random_state=42, cache_size=1000))\n",
        "])\n",
        "\n",
        "# Hyperparameter distributions\n",
        "param_dist_svm = {\n",
        "    'svm__C': loguniform(0.01, 100),\n",
        "    'svm__kernel': ['rbf', 'poly', 'sigmoid', 'linear'],\n",
        "    'svm__gamma': ['scale', 'auto'] + list(loguniform(1e-4, 1).rvs(8, random_state=42)),\n",
        "    'svm__degree': [2, 3, 4],\n",
        "    'svm__coef0': uniform(0, 1),\n",
        "    'svm__class_weight': [None, 'balanced'],\n",
        "    'svm__shrinking': [True, False],\n",
        "    'svm__tol': loguniform(1e-5, 1e-2),\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV\n",
        "random_search_svm = RandomizedSearchCV(\n",
        "    pipeline_svm, param_dist_svm, n_iter=15, cv=5, scoring='accuracy',\n",
        "    n_jobs=-1, verbose=2, random_state=42, return_train_score=True\n",
        ")\n",
        "\n",
        "print(\"Starting SVM training (30 models, 5-fold CV)...\")\n",
        "random_search_svm.fit(X_train_svm, y_train_svm)\n",
        "\n",
        "# Top 5 results\n",
        "results_svm = pd.DataFrame(random_search_svm.cv_results_).sort_values('rank_test_score')\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"=== SVM: Top 5 Parameter Combinations ===\")\n",
        "print(\"=\"*60)\n",
        "for _, row in results_svm.head(5).iterrows():\n",
        "    print(f\"\\nRank {int(row['rank_test_score'])}:\")\n",
        "    print(f\"  C={row['param_svm__C']:.4f}, kernel={row['param_svm__kernel']}, gamma={row['param_svm__gamma']}\")\n",
        "    print(f\"  CV Accuracy = {row['mean_test_score']:.4f} (+/- {row['std_test_score']:.4f})\")\n",
        "\n",
        "print(f\"\\nBest CV Accuracy: {random_search_svm.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate and predict\n",
        "best_svm = random_search_svm.best_estimator_\n",
        "y_pred_svm = best_svm.predict(X_test_svm)\n",
        "print(f\"\\nTest Accuracy: {accuracy_score(y_test_svm, y_pred_svm):.4f}\")\n",
        "print(classification_report(y_test_svm, y_pred_svm))\n",
        "\n",
        "# Submission\n",
        "submission_svm = pd.DataFrame({\n",
        "    'id': range(len(test_df_svm)),\n",
        "    'smoking': best_svm.predict(test_df_svm)\n",
        "})\n",
        "submission_svm.to_csv('svm_submission.csv', index=False)\n",
        "print(f\"Submission 'svm_submission.csv' created: {len(submission_svm)} predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "010f4b02",
      "metadata": {},
      "source": [
        "## Neural Network (MLPClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa77f945",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline\n",
        "pipeline_mlp = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('mlp', MLPClassifier(random_state=42, early_stopping=True, validation_fraction=0.1))\n",
        "])\n",
        "\n",
        "# Hyperparameter distributions\n",
        "param_dist_mlp = {\n",
        "    'mlp__hidden_layer_sizes': [\n",
        "        (64,), (128,), (256,),\n",
        "        (64, 32), (128, 64), (256, 128),\n",
        "        (128, 64, 32), (256, 128, 64),\n",
        "        (64, 64), (128, 128), (100, 50, 25)\n",
        "    ],\n",
        "    'mlp__activation': ['relu', 'tanh', 'logistic'],\n",
        "    'mlp__solver': ['adam', 'sgd'],\n",
        "    'mlp__learning_rate': ['constant', 'adaptive', 'invscaling'],\n",
        "    'mlp__learning_rate_init': loguniform(1e-4, 1e-1),\n",
        "    'mlp__alpha': loguniform(1e-5, 1e-1),\n",
        "    'mlp__batch_size': [32, 64, 128, 256],\n",
        "    'mlp__max_iter': [300, 500, 700, 1000],\n",
        "    'mlp__beta_1': uniform(0.85, 0.14),\n",
        "    'mlp__beta_2': uniform(0.99, 0.009),\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV\n",
        "random_search_mlp = RandomizedSearchCV(\n",
        "    pipeline_mlp, param_dist_mlp, n_iter=15, cv=5, scoring='accuracy',\n",
        "    n_jobs=-1, verbose=2, random_state=42, return_train_score=True\n",
        ")\n",
        "\n",
        "print(\"Starting MLP training (30 models, 5-fold CV)...\")\n",
        "random_search_mlp.fit(X_train_mlp, y_train_mlp)\n",
        "\n",
        "# Top 5 results\n",
        "results_mlp = pd.DataFrame(random_search_mlp.cv_results_).sort_values('rank_test_score')\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"=== MLP: Top 5 Parameter Combinations ===\")\n",
        "print(\"=\"*60)\n",
        "for _, row in results_mlp.head(5).iterrows():\n",
        "    print(f\"\\nRank {int(row['rank_test_score'])}:\")\n",
        "    print(f\"  layers={row['param_mlp__hidden_layer_sizes']}, activation={row['param_mlp__activation']}\")\n",
        "    print(f\"  solver={row['param_mlp__solver']}, lr_init={row['param_mlp__learning_rate_init']:.6f}\")\n",
        "    print(f\"  CV Accuracy = {row['mean_test_score']:.4f} (+/- {row['std_test_score']:.4f})\")\n",
        "\n",
        "print(f\"\\nBest CV Accuracy: {random_search_mlp.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate and predict\n",
        "best_mlp = random_search_mlp.best_estimator_\n",
        "y_pred_mlp = best_mlp.predict(X_test_mlp)\n",
        "print(f\"\\nTest Accuracy: {accuracy_score(y_test_mlp, y_pred_mlp):.4f}\")\n",
        "print(classification_report(y_test_mlp, y_pred_mlp))\n",
        "\n",
        "# Submission\n",
        "submission_mlp = pd.DataFrame({\n",
        "    'id': range(len(test_df_mlp)),\n",
        "    'smoking': best_mlp.predict(test_df_mlp)\n",
        "})\n",
        "submission_mlp.to_csv('mlp_submission.csv', index=False)\n",
        "print(f\"Submission 'mlp_submission.csv' created: {len(submission_mlp)} predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "599cb515",
      "metadata": {},
      "source": [
        "## Model Comparison - Classification Scores Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4124fe68",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "#                    MODEL COMPARISON SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "# Collect all results\n",
        "models_data = {\n",
        "    'Logistic Regression': {\n",
        "        'y_test': y_test_lr, 'y_pred': y_pred_lr, 'cv_score': random_search_lr.best_score_\n",
        "    },\n",
        "    'SVM': {\n",
        "        'y_test': y_test_svm, 'y_pred': y_pred_svm, 'cv_score': random_search_svm.best_score_\n",
        "    },\n",
        "    'Neural Network (MLP)': {\n",
        "        'y_test': y_test_mlp, 'y_pred': y_pred_mlp, 'cv_score': random_search_mlp.best_score_\n",
        "    }\n",
        "}\n",
        "\n",
        "# Calculate metrics\n",
        "model_results = {}\n",
        "for name, data in models_data.items():\n",
        "    model_results[name] = {\n",
        "        'Test Accuracy': accuracy_score(data['y_test'], data['y_pred']),\n",
        "        'Precision': precision_score(data['y_test'], data['y_pred'], average='weighted'),\n",
        "        'Recall': recall_score(data['y_test'], data['y_pred'], average='weighted'),\n",
        "        'F1-Score': f1_score(data['y_test'], data['y_pred'], average='weighted'),\n",
        "        'CV Score': data['cv_score']\n",
        "    }\n",
        "\n",
        "# Print comparison table\n",
        "print(\"=\"*80)\n",
        "print(\"                    FINAL MODEL COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n{'MODEL':<25} {'ACCURACY':>12} {'PRECISION':>12} {'RECALL':>12} {'F1-SCORE':>12}\")\n",
        "print(\"-\"*80)\n",
        "for name, scores in model_results.items():\n",
        "    print(f\"{name:<25} {scores['Test Accuracy']:>12.4f} {scores['Precision']:>12.4f} \"\n",
        "          f\"{scores['Recall']:>12.4f} {scores['F1-Score']:>12.4f}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Best model\n",
        "best_model = max(model_results, key=lambda x: model_results[x]['Test Accuracy'])\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model} (Accuracy: {model_results[best_model]['Test Accuracy']:.4f})\")\n",
        "\n",
        "# Summary DataFrame\n",
        "summary_df = pd.DataFrame(model_results).T.round(4).sort_values('Test Accuracy', ascending=False)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY TABLE\")\n",
        "print(\"=\"*80)\n",
        "print(summary_df)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUBMISSION FILES: logistic_submission.csv, svm_submission.csv, mlp_submission.csv\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
