{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "20026b8a",
      "metadata": {},
      "source": [
        "# Forest Cover Type ‚Äì Training Notebook\n",
        "Algorithms: Logistic Regression, SVM, MLP Neural Network.\n",
        "\n",
        "**Goal:** Achieve best accuracy using optimized model configurations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4254fb05",
      "metadata": {},
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "142dc6e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 464809\n",
            "Test set size: 116203\n",
            "Number of features: 54\n",
            "Number of classes: 7\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"covtype.csv\")\n",
        "\n",
        "X = df.drop(columns=[\"Cover_Type\"])\n",
        "y = df[\"Cover_Type\"]\n",
        "\n",
        "# Train-test split with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature scaling (important for SVM and MLP)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n",
        "print(f\"Number of features: {X_train.shape[1]}\")\n",
        "print(f\"Number of classes: {len(np.unique(y))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7af21714",
      "metadata": {},
      "source": [
        "## 2. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fedffe94",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.7234\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.71      0.70      0.70     42368\n",
            "           2       0.75      0.80      0.77     56661\n",
            "           3       0.68      0.80      0.73      7151\n",
            "           4       0.61      0.44      0.51       549\n",
            "           5       0.14      0.00      0.01      1899\n",
            "           6       0.49      0.27      0.35      3473\n",
            "           7       0.74      0.56      0.63      4102\n",
            "\n",
            "    accuracy                           0.72    116203\n",
            "   macro avg       0.59      0.51      0.53    116203\n",
            "weighted avg       0.71      0.72      0.71    116203\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression with optimized parameters\n",
        "lr = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    solver='lbfgs',\n",
        "    multi_class='multinomial',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "lr.fit(X_train, y_train)\n",
        "pred_lr = lr.predict(X_test)\n",
        "\n",
        "lr_accuracy = accuracy_score(y_test, pred_lr)\n",
        "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\n",
        "print(classification_report(y_test, pred_lr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8c142ef",
      "metadata": {},
      "source": [
        "## 3. Support Vector Machine (LinearSVC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04540c0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LinearSVC with optimized parameters\n",
        "svm = LinearSVC(\n",
        "    C=1.0,\n",
        "    max_iter=2000,\n",
        "    dual=True,\n",
        "    random_state=42\n",
        ")\n",
        "svm.fit(X_train, y_train)\n",
        "pred_svm = svm.predict(X_test)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, pred_svm)\n",
        "print(f\"SVM (LinearSVC) Accuracy: {svm_accuracy:.4f}\")\n",
        "print(classification_report(y_test, pred_svm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07c607d5",
      "metadata": {},
      "source": [
        "## 4. Neural Network (MLPClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e65df93",
      "metadata": {},
      "outputs": [],
      "source": [
        "# MLP Neural Network with optimized hyperparameters\n",
        "# Based on grid search results from reference, (100, 100) hidden layers work best\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 100),\n",
        "    max_iter=300,\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    alpha=0.0001,\n",
        "    batch_size='auto',\n",
        "    learning_rate='adaptive',\n",
        "    learning_rate_init=0.001,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1,\n",
        "    n_iter_no_change=10,\n",
        "    random_state=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Training MLP Neural Network...\")\n",
        "mlp.fit(X_train, y_train)\n",
        "pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "mlp_accuracy = accuracy_score(y_test, pred_mlp)\n",
        "print(f\"\\nMLP Neural Network Accuracy: {mlp_accuracy:.4f}\")\n",
        "print(classification_report(y_test, pred_mlp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1f46735",
      "metadata": {},
      "source": [
        "## 5. MLP with Grid Search (Optional - for best accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279842a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid Search for MLP to find optimal hyperparameters\n",
        "# Note: This may take several minutes to run\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(100,), (200,), (100, 100), (100, 50)],\n",
        "    'activation': ['relu'],\n",
        "    'solver': ['adam'],\n",
        "    'alpha': [0.0001, 0.001],\n",
        "    'learning_rate': ['adaptive'],\n",
        "    'max_iter': [200]\n",
        "}\n",
        "\n",
        "mlp_gs = MLPClassifier(\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1,\n",
        "    n_iter_no_change=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Running Grid Search for MLP (this may take a while)...\")\n",
        "grid_search = GridSearchCV(\n",
        "    mlp_gs, \n",
        "    param_grid, \n",
        "    cv=3, \n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "best_mlp = grid_search.best_estimator_\n",
        "pred_best_mlp = best_mlp.predict(X_test)\n",
        "best_mlp_accuracy = accuracy_score(y_test, pred_best_mlp)\n",
        "print(f\"Best MLP Test Accuracy: {best_mlp_accuracy:.4f}\")\n",
        "print(classification_report(y_test, pred_best_mlp))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e503e08",
      "metadata": {},
      "source": [
        "## 6. Model Comparison Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c49df52",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Comparison Summary\n",
        "import pandas as pd\n",
        "\n",
        "results = {\n",
        "    'Model': ['Logistic Regression', 'SVM (LinearSVC)', 'MLP Neural Network', 'MLP (Grid Search)'],\n",
        "    'Accuracy': [lr_accuracy, svm_accuracy, mlp_accuracy, best_mlp_accuracy]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"MODEL COMPARISON - FOREST COVER TYPE PREDICTION\")\n",
        "print(\"=\" * 50)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nüèÜ Best Model: {results_df.iloc[0]['Model']}\")\n",
        "print(f\"   Best Accuracy: {results_df.iloc[0]['Accuracy']:.4f} ({results_df.iloc[0]['Accuracy']*100:.2f}%)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
