{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "20026b8a",
      "metadata": {},
      "source": [
        "# Forest Cover Type ‚Äì Training Notebook\n",
        "Algorithms: Logistic Regression, SVM, MLP Neural Network.\n",
        "\n",
        "**Goal:** Achieve best accuracy using optimized model configurations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4254fb05",
      "metadata": {},
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "142dc6e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Shape: (581012, 55)\n",
            "\n",
            "Column Names:\n",
            "['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Cover_Type']\n",
            "\n",
            "Numerical features (10): ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n",
            "Binary features (44): Wilderness_Area (4) + Soil_Type (40)\n",
            "\n",
            "Missing values: 0\n",
            "\n",
            "Training set size: 464809\n",
            "Test set size: 116203\n",
            "Number of features: 54\n",
            "Number of classes: 7\n",
            "Class distribution:\n",
            "Cover_Type\n",
            "1    211840\n",
            "2    283301\n",
            "3     35754\n",
            "4      2747\n",
            "5      9493\n",
            "6     17367\n",
            "7     20510\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"covtype.csv\")\n",
        "\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nColumn Names:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=[\"Cover_Type\"])\n",
        "y = df[\"Cover_Type\"]\n",
        "\n",
        "# Identify numerical columns (continuous features - need scaling)\n",
        "numerical_cols = ['Elevation', 'Aspect', 'Slope', \n",
        "                  'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
        "                  'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
        "                  'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n",
        "\n",
        "# Identify binary columns (already one-hot encoded - no scaling needed)\n",
        "wilderness_cols = [col for col in X.columns if col.startswith('Wilderness_Area')]\n",
        "soil_cols = [col for col in X.columns if col.startswith('Soil_Type')]\n",
        "binary_cols = wilderness_cols + soil_cols\n",
        "\n",
        "print(f\"\\nNumerical features ({len(numerical_cols)}): {numerical_cols}\")\n",
        "print(f\"Binary features ({len(binary_cols)}): Wilderness_Area (4) + Soil_Type (40)\")\n",
        "\n",
        "# Check for missing values\n",
        "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
        "\n",
        "# Train-test split with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Create preprocessing pipeline - scale only numerical features\n",
        "# Binary features (Wilderness_Area and Soil_Type) remain unchanged\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('bin', 'passthrough', binary_cols)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Fit and transform the data\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "print(f\"\\nTraining set size: {X_train_processed.shape[0]}\")\n",
        "print(f\"Test set size: {X_test_processed.shape[0]}\")\n",
        "print(f\"Number of features: {X_train_processed.shape[1]}\")\n",
        "print(f\"Number of classes: {len(np.unique(y))}\")\n",
        "print(f\"Class distribution:\\n{y.value_counts().sort_index()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7af21714",
      "metadata": {},
      "source": [
        "## 2. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fedffe94",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.7234\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.71      0.70      0.70     42368\n",
            "           2       0.75      0.80      0.77     56661\n",
            "           3       0.68      0.80      0.73      7151\n",
            "           4       0.60      0.43      0.50       549\n",
            "           5       0.17      0.01      0.01      1899\n",
            "           6       0.50      0.28      0.36      3473\n",
            "           7       0.74      0.56      0.63      4102\n",
            "\n",
            "    accuracy                           0.72    116203\n",
            "   macro avg       0.59      0.51      0.53    116203\n",
            "weighted avg       0.71      0.72      0.71    116203\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression with optimized parameters\n",
        "# Note: 'multi_class' parameter removed (deprecated in sklearn 1.3+)\n",
        "# sklearn now automatically uses multinomial for multi-class problems\n",
        "lr = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    solver='lbfgs',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "lr.fit(X_train_processed, y_train)\n",
        "pred_lr = lr.predict(X_test_processed)\n",
        "\n",
        "lr_accuracy = accuracy_score(y_test, pred_lr)\n",
        "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\n",
        "print(classification_report(y_test, pred_lr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8c142ef",
      "metadata": {},
      "source": [
        "## 3. Support Vector Machine (LinearSVC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "04540c0a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM (LinearSVC) Accuracy: 0.7114\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.71      0.68      0.69     42368\n",
            "           2       0.73      0.80      0.76     56661\n",
            "           3       0.61      0.87      0.72      7151\n",
            "           4       0.62      0.20      0.30       549\n",
            "           5       0.56      0.01      0.02      1899\n",
            "           6       0.43      0.06      0.10      3473\n",
            "           7       0.68      0.51      0.58      4102\n",
            "\n",
            "    accuracy                           0.71    116203\n",
            "   macro avg       0.62      0.45      0.46    116203\n",
            "weighted avg       0.70      0.71      0.70    116203\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# LinearSVC with optimized parameters\n",
        "svm = LinearSVC(\n",
        "    C=1.0,\n",
        "    max_iter=2000,\n",
        "    dual=True,\n",
        "    random_state=42\n",
        ")\n",
        "svm.fit(X_train_processed, y_train)\n",
        "pred_svm = svm.predict(X_test_processed)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, pred_svm)\n",
        "print(f\"SVM (LinearSVC) Accuracy: {svm_accuracy:.4f}\")\n",
        "print(classification_report(y_test, pred_svm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07c607d5",
      "metadata": {},
      "source": [
        "## 4. Neural Network (MLPClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0e65df93",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MLP Neural Network...\n",
            "Iteration 1, loss = 0.57007138\n",
            "Validation score: 0.794518\n",
            "Iteration 2, loss = 0.45201054\n",
            "Validation score: 0.821970\n",
            "Iteration 3, loss = 0.40961381\n",
            "Validation score: 0.835632\n",
            "Iteration 4, loss = 0.38298840\n",
            "Validation score: 0.839827\n",
            "Iteration 5, loss = 0.36257820\n",
            "Validation score: 0.849207\n",
            "Iteration 6, loss = 0.34666147\n",
            "Validation score: 0.860373\n",
            "Iteration 7, loss = 0.33391534\n",
            "Validation score: 0.862546\n",
            "Iteration 8, loss = 0.32384433\n",
            "Validation score: 0.868247\n",
            "Iteration 9, loss = 0.31554927\n",
            "Validation score: 0.871517\n",
            "Iteration 10, loss = 0.30730135\n",
            "Validation score: 0.876035\n",
            "Iteration 11, loss = 0.30156292\n",
            "Validation score: 0.874852\n",
            "Iteration 12, loss = 0.29512467\n",
            "Validation score: 0.873217\n",
            "Iteration 13, loss = 0.28954229\n",
            "Validation score: 0.883953\n",
            "Iteration 14, loss = 0.28478956\n",
            "Validation score: 0.883114\n",
            "Iteration 15, loss = 0.28021918\n",
            "Validation score: 0.881694\n",
            "Iteration 16, loss = 0.27637071\n",
            "Validation score: 0.886341\n",
            "Iteration 17, loss = 0.27239547\n",
            "Validation score: 0.889008\n",
            "Iteration 18, loss = 0.26917623\n",
            "Validation score: 0.885566\n",
            "Iteration 19, loss = 0.26513183\n",
            "Validation score: 0.887137\n",
            "Iteration 20, loss = 0.26258511\n",
            "Validation score: 0.891117\n",
            "Iteration 21, loss = 0.25907507\n",
            "Validation score: 0.889568\n",
            "Iteration 22, loss = 0.25615092\n",
            "Validation score: 0.884856\n",
            "Iteration 23, loss = 0.25483226\n",
            "Validation score: 0.894021\n",
            "Iteration 24, loss = 0.25194584\n",
            "Validation score: 0.894989\n",
            "Iteration 25, loss = 0.24961263\n",
            "Validation score: 0.896087\n",
            "Iteration 26, loss = 0.24754732\n",
            "Validation score: 0.895377\n",
            "Iteration 27, loss = 0.24486879\n",
            "Validation score: 0.895441\n",
            "Iteration 28, loss = 0.24268150\n",
            "Validation score: 0.894925\n",
            "Iteration 29, loss = 0.24170702\n",
            "Validation score: 0.895914\n",
            "Iteration 30, loss = 0.23898965\n",
            "Validation score: 0.900949\n",
            "Iteration 31, loss = 0.23827752\n",
            "Validation score: 0.902154\n",
            "Iteration 32, loss = 0.23547336\n",
            "Validation score: 0.903186\n",
            "Iteration 33, loss = 0.23396804\n",
            "Validation score: 0.896237\n",
            "Iteration 34, loss = 0.23198619\n",
            "Validation score: 0.901056\n",
            "Iteration 35, loss = 0.23052948\n",
            "Validation score: 0.904068\n",
            "Iteration 36, loss = 0.22922446\n",
            "Validation score: 0.896754\n",
            "Iteration 37, loss = 0.22807256\n",
            "Validation score: 0.902928\n",
            "Iteration 38, loss = 0.22593330\n",
            "Validation score: 0.904757\n",
            "Iteration 39, loss = 0.22464807\n",
            "Validation score: 0.906327\n",
            "Iteration 40, loss = 0.22395479\n",
            "Validation score: 0.909834\n",
            "Iteration 41, loss = 0.22264263\n",
            "Validation score: 0.903229\n",
            "Iteration 42, loss = 0.22129310\n",
            "Validation score: 0.903789\n",
            "Iteration 43, loss = 0.21938590\n",
            "Validation score: 0.908952\n",
            "Iteration 44, loss = 0.21838345\n",
            "Validation score: 0.898862\n",
            "Iteration 45, loss = 0.21741968\n",
            "Validation score: 0.905510\n",
            "Iteration 46, loss = 0.21627397\n",
            "Validation score: 0.909189\n",
            "Iteration 47, loss = 0.21469466\n",
            "Validation score: 0.909060\n",
            "Iteration 48, loss = 0.21412115\n",
            "Validation score: 0.904391\n",
            "Iteration 49, loss = 0.21428562\n",
            "Validation score: 0.908888\n",
            "Iteration 50, loss = 0.21126752\n",
            "Validation score: 0.911620\n",
            "Iteration 51, loss = 0.21146414\n",
            "Validation score: 0.910652\n",
            "Iteration 52, loss = 0.20978525\n",
            "Validation score: 0.909382\n",
            "Iteration 53, loss = 0.20973287\n",
            "Validation score: 0.908113\n",
            "Iteration 54, loss = 0.20835313\n",
            "Validation score: 0.912502\n",
            "Iteration 55, loss = 0.20757186\n",
            "Validation score: 0.911297\n",
            "Iteration 56, loss = 0.20586062\n",
            "Validation score: 0.909425\n",
            "Iteration 57, loss = 0.20541543\n",
            "Validation score: 0.913040\n",
            "Iteration 58, loss = 0.20450138\n",
            "Validation score: 0.915019\n",
            "Iteration 59, loss = 0.20433478\n",
            "Validation score: 0.912696\n",
            "Iteration 60, loss = 0.20366264\n",
            "Validation score: 0.907876\n",
            "Iteration 61, loss = 0.20223248\n",
            "Validation score: 0.913018\n",
            "Iteration 62, loss = 0.20141990\n",
            "Validation score: 0.908457\n",
            "Iteration 63, loss = 0.20142912\n",
            "Validation score: 0.912911\n",
            "Iteration 64, loss = 0.20020128\n",
            "Validation score: 0.912997\n",
            "Iteration 65, loss = 0.20020877\n",
            "Validation score: 0.913298\n",
            "Iteration 66, loss = 0.19927842\n",
            "Validation score: 0.914696\n",
            "Iteration 67, loss = 0.19843322\n",
            "Validation score: 0.916998\n",
            "Iteration 68, loss = 0.19935428\n",
            "Validation score: 0.917063\n",
            "Iteration 69, loss = 0.19746279\n",
            "Validation score: 0.908866\n",
            "Iteration 70, loss = 0.19613713\n",
            "Validation score: 0.916331\n",
            "Iteration 71, loss = 0.19626397\n",
            "Validation score: 0.915449\n",
            "Iteration 72, loss = 0.19651841\n",
            "Validation score: 0.916116\n",
            "Iteration 73, loss = 0.19462529\n",
            "Validation score: 0.916740\n",
            "Iteration 74, loss = 0.19434917\n",
            "Validation score: 0.917235\n",
            "Iteration 75, loss = 0.19429465\n",
            "Validation score: 0.919107\n",
            "Iteration 76, loss = 0.19306372\n",
            "Validation score: 0.916396\n",
            "Iteration 77, loss = 0.19276147\n",
            "Validation score: 0.914158\n",
            "Iteration 78, loss = 0.19201883\n",
            "Validation score: 0.914804\n",
            "Iteration 79, loss = 0.19179354\n",
            "Validation score: 0.916116\n",
            "Iteration 80, loss = 0.19102000\n",
            "Validation score: 0.913298\n",
            "Iteration 81, loss = 0.19040070\n",
            "Validation score: 0.911964\n",
            "Iteration 82, loss = 0.19085383\n",
            "Validation score: 0.919171\n",
            "Iteration 83, loss = 0.18916198\n",
            "Validation score: 0.918397\n",
            "Iteration 84, loss = 0.18907845\n",
            "Validation score: 0.913384\n",
            "Iteration 85, loss = 0.18907793\n",
            "Validation score: 0.918332\n",
            "Iteration 86, loss = 0.18874038\n",
            "Validation score: 0.921409\n",
            "Iteration 87, loss = 0.18773873\n",
            "Validation score: 0.920268\n",
            "Iteration 88, loss = 0.18723976\n",
            "Validation score: 0.919709\n",
            "Iteration 89, loss = 0.18691764\n",
            "Validation score: 0.919042\n",
            "Iteration 90, loss = 0.18634847\n",
            "Validation score: 0.915621\n",
            "Iteration 91, loss = 0.18676422\n",
            "Validation score: 0.919279\n",
            "Iteration 92, loss = 0.18555242\n",
            "Validation score: 0.919623\n",
            "Iteration 93, loss = 0.18541996\n",
            "Validation score: 0.916912\n",
            "Iteration 94, loss = 0.18510508\n",
            "Validation score: 0.919279\n",
            "Iteration 95, loss = 0.18486233\n",
            "Validation score: 0.922936\n",
            "Iteration 96, loss = 0.18523988\n",
            "Validation score: 0.915837\n",
            "Iteration 97, loss = 0.18458272\n",
            "Validation score: 0.915277\n",
            "Iteration 98, loss = 0.18435539\n",
            "Validation score: 0.919042\n",
            "Iteration 99, loss = 0.18378574\n",
            "Validation score: 0.915127\n",
            "Iteration 100, loss = 0.18242081\n",
            "Validation score: 0.914352\n",
            "Iteration 101, loss = 0.18296408\n",
            "Validation score: 0.921581\n",
            "Iteration 102, loss = 0.18339741\n",
            "Validation score: 0.920613\n",
            "Iteration 103, loss = 0.18224517\n",
            "Validation score: 0.922893\n",
            "Iteration 104, loss = 0.18254004\n",
            "Validation score: 0.921839\n",
            "Iteration 105, loss = 0.18122966\n",
            "Validation score: 0.920161\n",
            "Iteration 106, loss = 0.18093388\n",
            "Validation score: 0.921151\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "\n",
            "MLP Neural Network Accuracy: 0.9221\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92     42368\n",
            "           2       0.93      0.93      0.93     56661\n",
            "           3       0.90      0.94      0.92      7151\n",
            "           4       0.88      0.81      0.84       549\n",
            "           5       0.86      0.77      0.81      1899\n",
            "           6       0.87      0.84      0.85      3473\n",
            "           7       0.96      0.91      0.93      4102\n",
            "\n",
            "    accuracy                           0.92    116203\n",
            "   macro avg       0.90      0.87      0.89    116203\n",
            "weighted avg       0.92      0.92      0.92    116203\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MLP Neural Network with optimized hyperparameters\n",
        "# Based on grid search results from reference, (100, 100) hidden layers work best\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 100),\n",
        "    max_iter=300,\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    alpha=0.0001,\n",
        "    batch_size='auto',\n",
        "    learning_rate='adaptive',\n",
        "    learning_rate_init=0.001,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1,\n",
        "    n_iter_no_change=10,\n",
        "    random_state=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Training MLP Neural Network...\")\n",
        "mlp.fit(X_train_processed, y_train)\n",
        "pred_mlp = mlp.predict(X_test_processed)\n",
        "\n",
        "mlp_accuracy = accuracy_score(y_test, pred_mlp)\n",
        "print(f\"\\nMLP Neural Network Accuracy: {mlp_accuracy:.4f}\")\n",
        "print(classification_report(y_test, pred_mlp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e503e08",
      "metadata": {},
      "source": [
        "## 6. Model Comparison Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1c49df52",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "MODEL COMPARISON - FOREST COVER TYPE PREDICTION\n",
            "==================================================\n",
            "              Model  Accuracy\n",
            " MLP Neural Network  0.922050\n",
            "Logistic Regression  0.723381\n",
            "    SVM (LinearSVC)  0.711410\n",
            "==================================================\n",
            "\n",
            "üèÜ Best Model: MLP Neural Network\n",
            "   Best Accuracy: 0.9221 (92.21%)\n"
          ]
        }
      ],
      "source": [
        "# Model Comparison Summary\n",
        "import pandas as pd\n",
        "\n",
        "results = {\n",
        "    'Model': ['Logistic Regression', 'SVM (LinearSVC)', 'MLP Neural Network'],\n",
        "    'Accuracy': [lr_accuracy, svm_accuracy, mlp_accuracy]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"MODEL COMPARISON - FOREST COVER TYPE PREDICTION\")\n",
        "print(\"=\" * 50)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nüèÜ Best Model: {results_df.iloc[0]['Model']}\")\n",
        "print(f\"   Best Accuracy: {results_df.iloc[0]['Accuracy']:.4f} ({results_df.iloc[0]['Accuracy']*100:.2f}%)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
